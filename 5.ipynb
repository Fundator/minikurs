{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning (DL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is it?\n",
    "\n",
    "Machine Learning based on artificial neural networks (NN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network\n",
    "\n",
    "_\"The universal approximation theorem of feed-forward neural networks states that every\n",
    "continuous function on a compact subset $R^n$ can be arbitrary well approximated by a\n",
    "feed-forward neural network with one hidden layer, a finite number of neurons, and some\n",
    "mild assumptions about the activation function\"_\n",
    "\n",
    "\n",
    "- What is a neuron?\n",
    "\n",
    "[<img src=\"resources/deep_learning/activition_function.png\" width=\"700\"/>](resources/deep_learning/activition_function.png)\n",
    "\n",
    "\n",
    "- What is a feed-forward neural network?\n",
    "\n",
    "[<img src=\"resources/deep_learning/neural_network_3.png\" width=\"500\"/>](resources/deep_learning/neural_network_3.png)\n",
    "\n",
    "\n",
    "\n",
    "- How can it fit a function at all?\n",
    "\n",
    "Simple approximation:\n",
    "[<img src=\"resources/deep_learning/simple_approx.png\" width=\"600\"/>](resources/deep_learning/simple_approx.png)\n",
    "\n",
    "Complex approximation:\n",
    "[<img src=\"resources/deep_learning/complex_approx.png\" width=\"600\"/>](resources/deep_learning/complex_approx.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Network\n",
    "\n",
    "_\"The number of linear regions in a feed-forward neural network grows exponentially with depth $L$ and polynomial\n",
    "with the number of neurons $n$ per hidden layer. Therefore, the number of linear regions grows much faster for deep architectures compared to shallow architectures with $nL$\n",
    "hidden neurons\"_\n",
    "\n",
    "ResNet, a deep residual neural network:\n",
    "\n",
    "[<img src=\"resources/deep_learning/ResNet.png\" width=\"800\"/>](resources/deep_learning/ResNet.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does it work?\n",
    "\n",
    "### Prediction by Forward pass\n",
    "\n",
    "A datapoint travels thorugh the network and creates a prediction.\n",
    "\n",
    "### Training by Backward pass\n",
    "\n",
    "A _loss function_ measures the incorrectness of a prediction. Training happends when _backpropagation_ first computes the gradient of the loss function the with respect to the weights and biases of the network for a single inputâ€“output example by using the _chain rule_, and secondly updates the weights and biases by using the _delta rule_.\n",
    "\n",
    "[<img src=\"resources/deep_learning/gradient_decent.jpeg\" width=\"800\"/>](resources/deep_learning/gradient_decent.jpeg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why is it useful?\n",
    "\n",
    "Since can arbitrary well approximate any relationship between input and output, it is usefull for complex data structures such as natrual language, images, audio and signals, time-series, or combinations of different data structures.\n",
    "\n",
    "Applications are\n",
    "\n",
    "- Natural Language Processing (NLP)\n",
    "- Image analysis\n",
    "- Audio and signal processing\n",
    "- Time-series forcasting\n",
    "- Reinforcement learning!\n",
    "\n",
    "From Papers with Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<img src=\"resources/deep_learning/application.png\" width=\"800\"/>](resources/deep_learning/application.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "print(\"CPU's:\", tf.config.list_physical_devices(\"CPU\"))\n",
    "print(\"GPU's:\", tf.config.list_physical_devices(\"GPU\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "'''\n",
    "flower_photo/\n",
    "  LICENSE.txt\n",
    "  daisy/\n",
    "  dandelion/\n",
    "  roses/\n",
    "  sunflowers/\n",
    "  tulips/\n",
    "'''\n",
    "\n",
    "roses = list(data_dir.glob('roses/*'))\n",
    "PIL.Image.open(str(roses[0]))\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT = 180\n",
    "IMG_WIDTH = 180\n",
    "IMG_DEPTH = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% Load using Dataset\n"
    }
   },
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(\"Image count:\", image_count)\n",
    "\n",
    "# Loads file names into dataset\n",
    "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'), shuffle=False)\n",
    "list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)\n",
    "\n",
    "val_size = int(image_count * 0.2)\n",
    "train_ds = list_ds.skip(val_size)\n",
    "val_ds = list_ds.take(val_size)\n",
    "\n",
    "class_names = np.array(sorted([item.name for item in data_dir.glob(\"*\") if item.name != \"LICENSE.txt\"]))\n",
    "print(\"Class names:\", class_names)\n",
    "\n",
    "print(\"Length of train dataset:\", tf.data.experimental.cardinality(train_ds).numpy())\n",
    "print(\"Length of val dataset:\", tf.data.experimental.cardinality(val_ds).numpy())\n",
    "\n",
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    one_hot = parts[-2] == class_names\n",
    "    return tf.argmax(one_hot)\n",
    "\n",
    "def decode_image(img):\n",
    "    img = tf.image.decode_jpeg(img, channels=IMG_DEPTH)\n",
    "    img = tf.image.resize(img, (IMG_HEIGHT, IMG_WIDTH))\n",
    "    return img\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_image(img)\n",
    "    return img, label\n",
    "\n",
    "train_ds = train_ds.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "val_ds = val_ds.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "for image, label in train_ds.take(1):\n",
    "    print(\"Image shape: \", image.numpy().shape)\n",
    "    print(\"Label: \", label.numpy())\n",
    "\n",
    "PIL.Image.fromarray(image.numpy().astype(\"uint8\"), \"RGB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note that the preprocessing code gives floats. Visualization must convert it to uint8 (0->255)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% Load using preprocessing\n"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=42)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=42)\n",
    "\n",
    "CLASS_NAMES = train_ds.class_names\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "# Display example image\n",
    "img, label = next(train_ds.take(1).as_numpy_iterator())\n",
    "img = img[0,:].astype(\"uint8\")\n",
    "print(\"Label:\", label[0])\n",
    "PIL.Image.fromarray(img, \"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% Visualize\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(CLASS_NAMES[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% Configure performance\n"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache().shuffle(1000) \\\n",
    "    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "val_ds = val_ds.cache() \\\n",
    "    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% Callbacks\n"
    }
   },
   "outputs": [],
   "source": [
    "# https://medium.com/ydata-ai/how-to-use-tensorflow-callbacks-f54f9bb6db25\n",
    "# tensorboard --logdir \"logs/image_classification\"\n",
    "\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    LearningRateScheduler,\n",
    "    ModelCheckpoint,\n",
    "    ReduceLROnPlateau,\n",
    "    TensorBoard,\n",
    ")\n",
    "\n",
    "def prepare_callbacks(model_name):\n",
    "    callbacks = []\n",
    "    timestamp = int(datetime.now().timestamp())\n",
    "    # EarlyStopping\n",
    "    early_stopping_patience = 5\n",
    "    callbacks.append(EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=early_stopping_patience, restore_best_weights=True))\n",
    "\n",
    "    # ModelCheckpoint\n",
    "    checkpoint_dir = \"./checkpoints/image_classification/\"\n",
    "    checkpoint_filepath = checkpoint_dir + str(timestamp) + \"_\" + model_name\n",
    "    # checkpoint_filepath = checkpoint_dir + 'checkpoint'\n",
    "\n",
    "    callbacks.append(ModelCheckpoint(\n",
    "        monitor=\"val_loss\", filepath=checkpoint_filepath, save_best_only=True, mode=\"min\"))\n",
    "\n",
    "    # Tensorboard\n",
    "    tensorboard_log_dir = f\"./logs/image_classification/{timestamp}\"\n",
    "    callbacks.append(TensorBoard(log_dir=tensorboard_log_dir))\n",
    "\n",
    "    # ReduceLROnPlateau\n",
    "    callbacks.append(ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.2, patience=5, min_lr=0.0005))\n",
    "\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% Define and compile model\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_compile_model(model_name, print_summary=False):\n",
    "    input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH)\n",
    "    model = tf.keras.models.Sequential(\n",
    "        layers=[\n",
    "            tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=input_shape),\n",
    "            tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "            tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "            tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "            tf.keras.layers.Conv2D(16, 3, padding='same', activation=\"relu\"),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            tf.keras.layers.Conv2D(32, 3, padding='same', activation=\"relu\"),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            tf.keras.layers.Conv2D(64, 3, padding='same', activation=\"relu\"),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\")],\n",
    "        name=model_name)\n",
    "\n",
    "    metrics = [tf.keras.metrics.CategoricalAccuracy()]\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "        loss=tf.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        metrics=metrics,\n",
    "    )\n",
    "\n",
    "    if print_summary:\n",
    "        print(model.summary())\n",
    "    \n",
    "    return model, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% Train\n"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "def train_model(epochs=EPOCHS):\n",
    "    model_name = input()\n",
    "    callbacks = prepare_callbacks(model_name)\n",
    "    model, metrics = create_compile_model(model_name, print_summary=True)\n",
    "    epochs=epochs\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    return history, metrics, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/92 [=============>................] - ETA: 23s - loss: 1.0394 - categorical_accuracy: 0.1908"
     ]
    }
   ],
   "source": [
    "history, metrics, model = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% plot metrices\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_metrics(history, metrics):\n",
    "    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    if not isinstance(metrics[0], str):\n",
    "        metrics = [metric.name for metric in metrics]\n",
    "    for n, metric in enumerate(metrics):\n",
    "        name = metric.replace(\"_\",\" \").capitalize()\n",
    "        plt.subplot((len(metrics) + 1) // 2,(len(metrics) + 1) // 2, n + 1)\n",
    "        plt.plot(history.epoch,  history.history[metric], color=colors[0], label='Train')\n",
    "        plt.plot(history.epoch, history.history['val_'+metric],\n",
    "                 color=colors[0], linestyle=\"--\", label='Val')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(name)\n",
    "        plt.legend()\n",
    "\n",
    "plot_metrics(history, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% plot loss\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    plt.plot(history.epoch,  history.history[\"loss\"], color=colors[0], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_loss'], color=colors[0], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% Get best model and evaluate\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_best_model():\n",
    "    \"\"\"Gets best model from checkpoints.\n",
    "    \n",
    "    Return (best model, model name, validation loss, categorical accuracy)\n",
    "    \"\"\"\n",
    "    loss_model = {}\n",
    "    for model_path in pathlib.Path(\"./checkpoints/image_classification\").glob(pattern=\"*\"):\n",
    "        model_name = model_path.name.split(\"/\")[-1]\n",
    "        loaded_model = tf.keras.models.load_model(model_path)\n",
    "        val_loss, categorical_accuracy = loaded_model.evaluate(val_ds)\n",
    "        loss_model[val_loss] = (loaded_model, model_name, val_loss, categorical_accuracy)\n",
    "        print(\"model name:\", model_name)\n",
    "        print(\"val_loss:\", round(val_loss,3))\n",
    "        print(\"categorical_accuracy:\", round(categorical_accuracy, 3))\n",
    "\n",
    "    return loss_model[min(loss_model.keys())]\n",
    "\n",
    "best_model, model_name, val_loss, categorical_accuracy = get_best_model()\n",
    "\n",
    "print(\"\\n\" + \"\".join([\"=\"]*25))\n",
    "print(\"Best model:\", model_name)\n",
    "print(\"Best val_loss:\", round(val_loss,3))\n",
    "print(\"Best categorical_accuracy:\", round(categorical_accuracy, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% View optimizer config\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "print(K.eval(best_model.optimizer.get_config()))\n",
    "print(best_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_plot(model, dataset):\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  for images, labels in dataset.take(1):\n",
    "    for i in range(9):\n",
    "      ax = plt.subplot(3, 3, i + 1)\n",
    "      pred = model.predict(tf.expand_dims(images[i],0))\n",
    "      pred_label = CLASS_NAMES[labels[np.argmax(pred)]]\n",
    "      true_label = CLASS_NAMES[labels[i]]\n",
    "      plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "      plt.title(f\"Pred: {pred_label}\\nTrue: {true_label}\")\n",
    "      plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predict_and_plot(best_model, val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained_model, _ = create_compile_model(\"untrained_model\")\n",
    "predict_and_plot(untrained_model, val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No free lunch theorem\n",
    "\n",
    "There are no free lunch, and espesially not within machine learning! Establish a baseline with the simplest possible solution first, then try to beat it.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0a06b1e484fd1b448386af0311754ceeab002272e77b8d19b3ff8a0c76025355"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
